# -*- coding: utf-8 -*-
"""Face_Mask_Detection_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bPNGYYw6-fzFX6W33gi5KuNVeVa9_eQx

# **Author:- SIBASIS SAHOO**
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torchvision import datasets,models,transforms
import numpy as np
import pandas as pd
from PIL import Image
import os
import cv2
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,roc_auc_score,classification_report
import shutil
import glob
import pickle
from google.colab.patches import cv2_imshow
from collections import OrderedDict

!git clone https://github.com/Sibasis555/Face_mask_detection

from zipfile import ZipFile
file_name="/content/Face_mask_detection/datasets/with_mask.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall('photos')
  print('done')
file_name="/content/Face_mask_detection/datasets/without_mask.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall('photos')
  print('done')

train_transform=transforms.Compose([
                              transforms.RandomRotation(10),
                              transforms.RandomHorizontalFlip(),
                              transforms.Resize(256),        
                              transforms.CenterCrop(224),    
                              transforms.ToTensor(),
                              transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])
])
test_transform=transforms.Compose([
                              transforms.Resize(224),
                              transforms.CenterCrop(224),
                              transforms.ToTensor(),
                              transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])
])

#creating folder for training, testing and validation
root = '/content/photos/'
os.makedirs(root +'/train/with_mask')
os.makedirs(root +'/train/without_mask')
os.makedirs(root +'/val/with_mask')
os.makedirs(root +'/val/without_mask')
os.makedirs(root +'/test/with_mask')
os.makedirs(root +'/test/without_mask')

#splitting images with mask to training, testing and validation folder
currentCls = '/with_mask'
src = "/content/photos/with_mask" # Folder to copy images from

allFileNames = os.listdir(src)
np.random.shuffle(allFileNames)
train_FileNames, test_FileNames, val_FileNames = np.split(np.array(allFileNames),
                                                          [int(len(allFileNames)*0.8),
                                                           int(len(allFileNames)*0.85)])
train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]
val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]
test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]
print('Total images: ', len(allFileNames))
print('Training: ', len(train_FileNames))
print('Validation: ', len(val_FileNames))
print('Testing: ', len(test_FileNames))

# Copy-pasting images
for name in train_FileNames:
    shutil.copy(name, "/content/photos/train"+currentCls)

for name in val_FileNames:
    shutil.copy(name, "/content/photos/val"+currentCls)

for name in test_FileNames:
    shutil.copy(name, "/content/photos/test"+currentCls)

#spliting images without_mask to training, testing and validation folder
currentCls = '/without_mask'
src = "/content/photos/without_mask" # Folder to copy images from

torch.manual_seed(42)

allFileNames = os.listdir(src)
np.random.shuffle(allFileNames)
train_FileNames, test_FileNames, val_FileNames = np.split(np.array(allFileNames),
                                                          [int(len(allFileNames)*0.8),
                                                           int(len(allFileNames)*0.85)])


train_FileNames = [src+'/'+ name for name in train_FileNames.tolist()]
val_FileNames = [src+'/' + name for name in val_FileNames.tolist()]
test_FileNames = [src+'/' + name for name in test_FileNames.tolist()]

print('Total images: ', len(allFileNames))
print('Training: ', len(train_FileNames))
print('Validation: ', len(val_FileNames))
print('Testing: ', len(test_FileNames))

# Copy-pasting images
for name in train_FileNames:
    shutil.copy(name, "/content/photos/train"+currentCls)

for name in val_FileNames:
    shutil.copy(name, "/content/photos/val"+currentCls)

for name in test_FileNames:
    shutil.copy(name, "/content/photos/test"+currentCls)

#transforming the images 
train_set=datasets.ImageFolder('/content/photos/train',transform=train_transform)
test_set=datasets.ImageFolder('/content/photos/test',transform=test_transform)
val_set=datasets.ImageFolder('/content/photos/val',transform=test_transform)
class_name=train_set.classes
class_name

#showing py-chart for number of data present in training, testing and validation folders
labels=len(train_set),len(test_set),len(val_set)
sizes=[len(train_set),len(test_set),len(val_set)]
#colors=['gold','blue','pink']
explode=(0,0.1,0)

#plot
plt.pie(sizes,explode=explode,labels=labels,autopct='%1.1f%%', shadow=True,startangle=90)
plt.axis('equal')

#showing some sample of images with_mask and without_mask
withmask=glob.glob('/content/photos/test/with_mask/*.jpg')
withoutmask=glob.glob('/content/photos/test/without_mask/*.jpg')

img=[]
non=[]
for i in withmask:
  a=Image.open(i)
  img.append(a)
for i in withoutmask:
  a=Image.open(i)
  non.append(a)
trans=transforms.ToPILImage()
tra=transforms.Resize(224)
tran=transforms.ToTensor()

ax1 = plt.subplot(2,2,1);
plt.imshow(trans(tran(tra(img[1]))))
ax2 = plt.subplot(2,2,2);
plt.imshow(trans(tran(tra(img[2]))))
ax3 = plt.subplot(2,2,3);
plt.imshow(trans(tran(tra(non[1]))))
ax4 = plt.subplot(2,2,4);
plt.imshow(trans(tran(tra(non[2]))))

seed=0
torch.manual_seed(seed)
if torch.cuda.is_available():
  torch.cuda.manual_seed_all(seed)

#converting to dataloder to make the batch_size
train_loader=DataLoader(train_set,batch_size=32,shuffle=True)
test_loader=DataLoader(test_set,batch_size=32)
val_loader=DataLoader(val_set,batch_size=32)

def alexnet_fc(model):
  from collections import OrderedDict
  model.classifier = nn.Sequential(OrderedDict([
                                              ('dp1', nn.Dropout(0.5)),
                                              ('fc1', nn.Linear(9216,256)),
                                              ('r1', nn.ReLU()),
                                              ('dp2', nn.Dropout(0.5)),
                                              ('fc2', nn.Linear(256,2)),
                                              ('out', nn.Softmax(dim=1))
  ]))
  return model

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
criterion=nn.CrossEntropyLoss().to(device)

def training(model,epochs,optimizer,criterion):
  import time
  start_time=time.time()

  train_losses=[]
  train_correct=[]
  #roc_auc=[]
  trn_per=[]
  val_per=[]
  y_pred=[]
  y_true=[]
  val_correct=[]
  val_losses=[]
  for i in range(epochs):
    trn_corr=0
    for b,(x_train,y_train) in enumerate(train_loader):
      if torch.cuda.is_available():
        x_train, y_train = x_train.cuda(), y_train.cuda()
      b+=1
      y_pred=model(x_train)
      loss=criterion(y_pred,y_train)
      #Tally the number of correct prediction
      predicted=torch.max(y_pred.data,1)[1]
      batch_corr=(predicted==y_train).sum()
      trn_corr+=batch_corr
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()
      #print updates
      if b%95 == 0:
        print(f'Epoch {i:2} batch:{b:4} [{32*b:6}/3056] Loss: {loss.item():10.8f}accuracy: {trn_corr.item()*100/(32*b):7.3f}%')
    train_losses.append(loss)
    total_per=trn_corr.item()/3056*100
    train_correct.append(total_per)
    #roc_auc.append(roc_auc_val)

    with torch.no_grad():
      val_corr=0
      for b,(x_valid,y_valid) in enumerate(test_loader):
        #Optional
        if torch.cuda.is_available():
          x_valid, y_valid = x_valid.cuda(), y_valid.cuda()

        b=b+1  
        y_val =model(x_valid)
        loss=criterion(y_val,y_valid)
        predicted=torch.max(y_val.data,1)[1]
        batch_corr=(predicted==y_valid).sum()
        val_corr+=batch_corr
        if b%5==0:
          print(f'Loss: {loss.item():10.8f} , accuracy: {val_corr.item()/(b*32)*100:7.3f}%')
      val_losses.append(loss)
      total_per=val_corr.item()/191*100
      val_correct.append(total_per)
  total_time=time.time() - start_time
  print(f'Total time: {total_time/60} minutes')
  return train_losses,train_correct,val_losses,val_correct

alexnet_model=models.alexnet(pretrained=True)
for param in alexnet_model.parameters():
  param.required_grad=False

alexnet_model

alexnet_model=alexnet_fc(alexnet_model)
alexnet_model.to(device)
optimizer5=torch.optim.Adam(alexnet_model.parameters(),lr=0.0001 )

alextrain_losses,alextrain_correct,alexval_losses,alexval_correct=training(model=alexnet_model,epochs=10,
                                                                           optimizer=optimizer5,
                                                                           criterion=criterion)

plt.plot(alextrain_losses,label='alexTraining Loss')
plt.plot(alexval_losses,label='alexTest loss')
#plt.plot(val_losses,label='validation loss')
plt.title('loss at epocs')
plt.legend()

plt.plot(alextrain_correct,label='alexTraining acc')
plt.plot(alexval_correct,label='alexTest acc')
#plt.plot(val_correct,label='val acc')
plt.legend()

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.model_selection import cross_val_score

#Test set
y_tst_pred=[]
y_tst_true=[]
test_losses=[]
test_correct=[]
with torch.no_grad():
    tst_corr=0
    for b,(x_test,y_test) in enumerate(val_loader):
      #Optional
      if torch.cuda.is_available():
         x_test,y_test = x_test.cuda(), y_test.cuda()
      '''if b==max_tst_batch:
        break'''
      b=b+1
      y_val =alexnet_model(x_test)
      loss=criterion(y_val,y_test)
      predicted=torch.max(y_val.data,1)[1]
      tst_corr+=(predicted==y_test).sum()
      y_tst_pred.append(predicted.cpu().numpy())
      y_tst_true.append(y_test.cpu().numpy())
      if b%18==0:
        print(f'Loss: {loss.item():10.8f} , accuracy: {tst_corr.item()/(32*b)*100:7.3f}%')
    test_losses.append(loss)
    test_correct.append(tst_corr)

y_tst_pred=np.array(y_tst_pred)
y_tst_pred=np.hstack(y_tst_pred).tolist()
y_tst_pred=np.array(y_tst_pred)
y_tst_true=np.array(y_tst_true)
y_tst_true=np.hstack(y_tst_true).tolist()
y_tst_true=np.array(y_tst_true)

print("Accuracy score: \n",accuracy_score(y_tst_true,y_tst_pred))
print("Confusion Matrix: \n",confusion_matrix(y_tst_true,y_tst_pred))
print("Classification report: \n",classification_report(y_tst_true,y_tst_pred))

fpr,tpr,thresholds=roc_curve(y_tst_true,y_tst_pred)
plt.plot(fpr,tpr,color='green')

roc_auc_score(y_tst_true,y_tst_pred)

filename = 'face_mask_detection_model.pkl'
pickle.dump(alexnet_model, open(filename, 'wb'))

